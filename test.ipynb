{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Agency</th>\n",
       "      <th>FHLMC</th>\n",
       "      <th>FNMA</th>\n",
       "      <th>GNMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/02/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/03/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/04/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/07/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/08/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/09/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/10/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/11/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/14/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/15/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/16/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/17/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/18/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/22/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/23/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/24/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/25/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/28/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/29/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/30/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/31/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/01/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/04/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/05/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/06/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/07/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/08/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/11/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/12/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/13/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/19/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/20/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/21/2019</th>\n",
       "      <td>103.7</td>\n",
       "      <td></td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/22/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/25/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/26/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/27/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/28/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/29/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/01/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/02/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/03/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/04/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/05/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/08/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/09/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/10/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/11/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/12/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/15/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/16/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/17/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/18/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/22/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/23/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/24/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/25/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/26/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/29/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/30/2019</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>101.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Agency      FHLMC FNMA   GNMA\n",
       "Date                         \n",
       "01/02/2019                   \n",
       "01/03/2019                   \n",
       "01/04/2019                   \n",
       "01/07/2019                   \n",
       "01/08/2019                   \n",
       "01/09/2019                   \n",
       "01/10/2019                   \n",
       "01/11/2019                   \n",
       "01/14/2019                   \n",
       "01/15/2019                   \n",
       "01/16/2019                   \n",
       "01/17/2019                   \n",
       "01/18/2019               99.3\n",
       "01/22/2019                   \n",
       "01/23/2019                   \n",
       "01/24/2019                   \n",
       "01/25/2019                   \n",
       "01/28/2019                   \n",
       "01/29/2019                   \n",
       "01/30/2019                   \n",
       "01/31/2019                   \n",
       "02/01/2019               99.6\n",
       "02/04/2019               99.6\n",
       "02/05/2019                   \n",
       "02/06/2019                   \n",
       "02/07/2019                   \n",
       "02/08/2019                   \n",
       "02/11/2019                   \n",
       "02/12/2019               99.5\n",
       "02/13/2019               99.1\n",
       "...           ...  ...    ...\n",
       "03/19/2019                   \n",
       "03/20/2019               98.9\n",
       "03/21/2019  103.7        99.6\n",
       "03/22/2019                   \n",
       "03/25/2019                   \n",
       "03/26/2019                   \n",
       "03/27/2019                   \n",
       "03/28/2019                   \n",
       "03/29/2019                   \n",
       "04/01/2019                   \n",
       "04/02/2019              100.2\n",
       "04/03/2019                   \n",
       "04/04/2019                   \n",
       "04/05/2019                   \n",
       "04/08/2019                   \n",
       "04/09/2019                   \n",
       "04/10/2019                   \n",
       "04/11/2019                   \n",
       "04/12/2019                   \n",
       "04/15/2019                   \n",
       "04/16/2019               99.5\n",
       "04/17/2019                   \n",
       "04/18/2019                   \n",
       "04/22/2019                   \n",
       "04/23/2019                   \n",
       "04/24/2019                   \n",
       "04/25/2019                   \n",
       "04/26/2019                   \n",
       "04/29/2019                   \n",
       "04/30/2019              101.1\n",
       "\n",
       "[82 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dfmbsfixed = pd.read_csv('mbspricesfixed.csv')\n",
    "dfmbsfixed.replace('*', '', inplace=True)\n",
    "dfmbsfixed.replace('0', '', inplace=True)\n",
    "dfmbsfixed[dfmbsfixed.columns[1:8]] = dfmbsfixed[dfmbsfixed.columns[1:8]].apply(pd.to_numeric)\n",
    "dfmbsfixed.replace(np.NaN, '', inplace=True)\n",
    "\n",
    "dfmbsfloating = pd.read_csv('mbspricesfloating.csv')\n",
    "dfmbsfloating.replace('*', '', inplace=True)\n",
    "dfmbsfloating.replace('0', '', inplace=True)\n",
    "dfmbsfloating[dfmbsfloating.columns[1:6]] = dfmbsfloating[dfmbsfloating.columns[1:6]].apply(pd.to_numeric)\n",
    "dfmbsfloating.replace(np.NaN, '', inplace=True)\n",
    "\n",
    "temp = dfmbsfloating[dfmbsfloating['Measure'] == 'AVERAGE PRICE']\n",
    "temp = temp[temp['Mortgage Type'] == 'ARMS/HYBRIDS']\n",
    "temp = temp.set_index(['Date', 'Agency']).unstack(level=1)\n",
    "temp['3/1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# takes a zip list of FINRA ABS trading files, cleans them up and spits them out into 2 raw CSV files.\n",
    "directory = os.fsencode('data')\n",
    "\n",
    "for zfile in os.listdir(directory):\n",
    "    filename = os.fsdecode(zfile)\n",
    "    zf = zipfile.ZipFile('data/' + filename)\n",
    "\n",
    "    # build namelist of specific files I need\n",
    "    star_list = [i for i in zf.namelist() if 'PXTABLES' in i]\n",
    "    \n",
    "    price_fields = ['AVERAGE PRICE', 'WEIGHTED AVG. PRICE', 'AVG. PRICE BOTTOM 5 TRADES', '2ND QUARTILE PRICE',\n",
    "                '3RD QUARTILE PRICE', '4TH QUARTILE PRICE', 'AVG. PRICE TOP 5 TRADES', 'STANDARD DEVIATION',\n",
    "                'VOLUME OF TRADES (000\\'S)', 'NUMBER OF TRADES']\n",
    "\n",
    "    for trading_day in star_list:\n",
    "        # get trading day date\n",
    "        trading_date = trading_day.split('-')[1].replace('.xlsx', '')\n",
    "\n",
    "        # should i fix trading date?\n",
    "        trading_date = '{}/{}/{}'.format(trading_date[4:6], trading_date[6:], trading_date[:4])\n",
    "\n",
    "        # testing on a single file\n",
    "        df = pd.read_excel(zf.open(trading_day), sheet_name='MBS', skiprows=8, header=None)\n",
    "        df.replace(np.NaN, '', inplace=True)\n",
    "        df = df.loc[:df[df[1].str.contains('Indicates')].index.values[0] - 2]\n",
    "        df[0] = df[1].where(df[1].str.contains('PRICING TABLE')).fillna(method='ffill')\n",
    "        df[0] = df[0].str.replace('PRICING TABLE: AGENCY PASS-THRU \\(SPECIFIED\\) - ', '')\n",
    "\n",
    "        df[9] = df[1].where(df[1].isin(price_fields))\n",
    "        df[10] = df[1].where(df[9].isna()).fillna(method='ffill')\n",
    "\n",
    "        #split the df in 2\n",
    "        df1 = df[~(df[0] == 'ARMS/HYBRIDS')].drop(1, axis=1).copy()\n",
    "        df2 = df[df[0] == 'ARMS/HYBRIDS'].copy()\n",
    "\n",
    "        df1.columns = df1[df1[9].isna() & ~(df1[8] == '')].iloc[0]\n",
    "        df1.columns.values[0], df1.columns.values[8], df1.columns.values[9]  = 'Mortgage Type', 'Measure', 'Agency'\n",
    "        df1 = df1[~(df1['Measure'].isna())]\n",
    "        df1['Date'] = trading_date\n",
    "\n",
    "        df2.drop([1, 7, 8], axis=1, inplace=True)\n",
    "        df2.columns = df2[df2[9].isna() & ~(df2[6] == '')].iloc[0]\n",
    "        df2.columns.values[0], df2.columns.values[6], df2.columns.values[7] = 'Mortgage Type', 'Measure', 'Agency'\n",
    "        df2 = df2[~(df2['Measure'].isna())]\n",
    "        df2['Date'] = trading_date\n",
    "\n",
    "        # check to see if filepath exists and append headers if they don't\n",
    "        if os.path.isfile('mbspricesfixed.csv'):\n",
    "            pass\n",
    "        else:\n",
    "            pd.DataFrame(df1.columns).transpose().to_csv('mbspricesfixed.csv', header=False, index=False, mode='a')\n",
    "\n",
    "        if os.path.isfile('mbspricesfloating.csv'):\n",
    "            pass\n",
    "        else:\n",
    "            pd.DataFrame(df2.columns).transpose().to_csv('mbspricesfloating.csv', header=False, index=False, mode='a')\n",
    "\n",
    "            # otherwise, append the file without  headers\n",
    "        df1.to_csv('mbspricesfixed.csv', header=False, index=False, mode='a')\n",
    "        df2.to_csv('mbspricesfloating.csv', header=False, index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
